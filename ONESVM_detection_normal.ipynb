{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Class SVM For Normal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "X_test=pd.read_csv(\"gener_normal.csv\")\n",
    "#Y_1=pd.read_csv(\"y_train1.csv\")\n",
    "train_feature=pd.read_csv(\"x_test_normal.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 121)\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.drop(['Unnamed: 0'],axis=1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1=np.ones((10000,), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "Y_test= pd.DataFrame(y_1)\n",
    "print(type(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing cols with rename() \n",
    "\n",
    "Y_test.columns=['Category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_gamma=0.0001\n",
    "one_nu=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have used various combination of hyperparameters like linear, rbf, poly, gamma- 0.001, 0.0001, nu- 0.25, 0.5, 0.75, 0.95\n",
    "oneclass = svm.OneClassSVM(kernel='linear', gamma=0.01, nu=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.01, kernel='linear',\n",
       "      max_iter=-1, nu=0.1, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Training the algorithm with the features. \n",
    "# This stage is very time consuming processes. In my laptop it took more than an hour to train for 200,000 observations. \n",
    "# For rbf, the time taken is even more.\n",
    "\n",
    "oneclass.fit(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the algorithm on the test set\n",
    "fraud_pred = oneclass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -1 1343]\n",
      " [   1 8657]]\n"
     ]
    }
   ],
   "source": [
    "# Check the number of outliers predicted by the algorithm\n",
    "\n",
    "unique, counts = np.unique(fraud_pred, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fraud_pred = pd.DataFrame(fraud_pred)\n",
    "fraud_pred= fraud_pred.rename(columns={0: 'prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8657\n"
     ]
    }
   ],
   "source": [
    "PP=fraud_pred[fraud_pred['prediction']==1]\n",
    "NP=fraud_pred[fraud_pred['prediction']==-1]\n",
    "number_test_data=10000\n",
    "#print(PP.head(2))\n",
    "P=PP.shape[0]\n",
    "N=NP.shape[0]\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=np.round(((P)/number_test_data)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.57\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Class SVM for Malware Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "X_test1=pd.read_csv(\"gener_DoS.csv\")\n",
    "#Y_1=pd.read_csv(\"y_train1.csv\")\n",
    "train_feature1=pd.read_csv(\"x_test_dos_mal.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 121)\n"
     ]
    }
   ],
   "source": [
    "X_test1 = X_test1.drop(['Unnamed: 0'],axis=1)\n",
    "print(X_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2=np.ones((10000,), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "Y_test1= pd.DataFrame(y_2)\n",
    "print(type(Y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test1.columns=['Category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneclass1 = svm.OneClassSVM(kernel='linear', gamma=0.001, nu=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_gamma1=0.001\n",
    "one_nu1=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
       "      max_iter=-1, nu=1e-05, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Training the algorithm with the features. \n",
    "# This stage is very time consuming processes. In my laptop it took more than an hour to train for 200,000 observations. \n",
    "# For rbf, the time taken is even more.\n",
    "\n",
    "oneclass1.fit(train_feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the algorithm on the test set\n",
    "fraud_pred1= oneclass.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -1 1949]\n",
      " [   1 8051]]\n"
     ]
    }
   ],
   "source": [
    "# Check the number of outliers predicted by the algorithm\n",
    "\n",
    "unique, counts = np.unique(fraud_pred1, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fraud_pred1 = pd.DataFrame(fraud_pred1)\n",
    "fraud_pred1= fraud_pred1.rename(columns={0: 'prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8051\n"
     ]
    }
   ],
   "source": [
    "PP1=fraud_pred[fraud_pred1['prediction']==1]\n",
    "NP1=fraud_pred[fraud_pred1['prediction']==-1]\n",
    "number_test_data1=10000\n",
    "#print(PP.head(2))\n",
    "P1=PP1.shape[0]\n",
    "N1=NP1.shape[0]\n",
    "print(P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc1=((P1)/number_test_data1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.51\n"
     ]
    }
   ],
   "source": [
    "print(acc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One SVM for Mix Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "X_test2=pd.read_csv(\"gener_mix.csv\")\n",
    "#Y_1=pd.read_csv(\"y_train1.csv\")\n",
    "train_feature2=pd.read_csv(\"x_test_mix.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = X_test2.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9998, 121)\n"
     ]
    }
   ],
   "source": [
    "print(train_feature2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3=np.ones((9700,), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "Y_test2= pd.DataFrame(y_3)\n",
    "print(type(Y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing cols with rename() \n",
    "\n",
    "Y_test2.columns=['Category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneclass2 = svm.OneClassSVM(kernel='linear', gamma=0.001, nu=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_gamma2=0.001\n",
    "one_nu2=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.001, kernel='linear',\n",
       "      max_iter=-1, nu=0.01, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Training the algorithm with the features. \n",
    "# This stage is very time consuming processes. In my laptop it took more than an hour to train for 200,000 observations. \n",
    "# For rbf, the time taken is even more.\n",
    "\n",
    "oneclass2.fit(train_feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the algorithm on the test set\n",
    "fraud_pred3 = oneclass2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -1  179]\n",
      " [   1 9521]]\n"
     ]
    }
   ],
   "source": [
    "# Check the number of outliers predicted by the algorithm\n",
    "\n",
    "unique, counts = np.unique(fraud_pred3, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_pred3 = pd.DataFrame(fraud_pred3)\n",
    "fraud_pred3= fraud_pred3.rename(columns={0: 'prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9521\n"
     ]
    }
   ],
   "source": [
    "PP2=fraud_pred3[fraud_pred3['prediction']==1]\n",
    "NP2=fraud_pred3[fraud_pred3['prediction']==-1]\n",
    "number_test_data2=9700\n",
    "#print(PP.head(2))\n",
    "P2=PP2.shape[0]\n",
    "N2=NP2.shape[0]\n",
    "print(P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2=np.round(((P2)/number_test_data2)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.15\n"
     ]
    }
   ],
   "source": [
    "print(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+------------+---------+-----------+\n",
      "| S.NO. |     MODEL     | Best Alpha | Best Nu | Auccuracy |\n",
      "+-------+---------------+------------+---------+-----------+\n",
      "|   1   | ONESVM_normal |   0.0001   |   0.25  |   86.57   |\n",
      "|   2   |   ONESVM_mal  |   0.001    |  1e-05  |   80.51   |\n",
      "|   3   |   ONESVM_mix  |   0.001    |  1e-05  |   98.15   |\n",
      "+-------+---------------+------------+---------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Creating table using PrettyTable library\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "names = [\"ONESVM_normal\",\"ONESVM_mal\" ,\"ONESVM_mix\"]\n",
    "         \n",
    "    \n",
    "optimal_gamma= [one_gamma,one_gamma1,one_gamma2]\n",
    "optimal_nu = [one_nu,one_nu1,one_nu2]\n",
    "\n",
    "test_auc_score = [acc,acc1,acc2]\n",
    "\n",
    "numbering = [1,2,3]\n",
    "\n",
    "# Initializing prettytable\n",
    "ptable = PrettyTable()\n",
    "\n",
    "# Adding columns\n",
    "ptable.add_column(\"S.NO.\",numbering)\n",
    "ptable.add_column(\"MODEL\",names)\n",
    "ptable.add_column(\"Best Alpha\",optimal_gamma)\n",
    "ptable.add_column(\"Best Nu\",optimal_nu)\n",
    "ptable.add_column(\"Auccuracy\",test_auc_score)\n",
    "# Printing the Table\n",
    "print(ptable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
